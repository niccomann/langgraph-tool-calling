{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-05T23:07:40.925805Z",
     "start_time": "2024-06-05T23:07:40.156996Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "## https://python.langchain.com/v0.1/docs/modules/tools/tools_as_openai_functions/\n",
    "## https://python.langchain.com/v0.2/docs/how_to/tools_as_openai_functions/\n",
    "## https://platform.openai.com/docs/guides/function-calling\n",
    "from langchain_community.tools import MoveFileTool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# @tool\n",
    "# def stampa_qualcosa():\n",
    "#     \"\"\"stampa qualcosa\"\"\"\n",
    "#     print('ok')\n",
    "#     return 'ok'\n",
    "# \n",
    "# tools = [stampa_qualcosa]\n",
    "# format_tool_to_openai_function(tools[0])\n",
    "# functions = [convert_to_openai_function(t) for t in tools]\n",
    "# \n",
    "# functions[0]\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "tools = [MoveFileTool()]\n",
    "functions = [convert_to_openai_function(t) for t in tools]\n",
    "\n",
    "functions[0]\n",
    "\n",
    "message = model.invoke(\n",
    "    [HumanMessage(content=\"move file foo to bar\")], functions=functions\n",
    ")\n",
    "message\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"source_path\":\"foo\",\"destination_path\":\"bar\"}', 'name': 'move_file'}}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 77, 'total_tokens': 97}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-8ad694f7-0379-4623-ae3f-8c064df20218-0', usage_metadata={'input_tokens': 77, 'output_tokens': 20, 'total_tokens': 97})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T09:39:18.567896Z",
     "start_time": "2024-06-06T09:39:16.951052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "## https://python.langchain.com/v0.1/docs/modules/tools/tools_as_openai_functions/\n",
    "## https://python.langchain.com/v0.2/docs/how_to/tools_as_openai_functions/\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "from langchain_community.tools import MoveFileTool\n",
    "\n",
    "\n",
    "@tool\n",
    "def info_messico(request: Annotated[str, \"A formatted HTTP request to send to the api https://api.example.com/\"]):\n",
    "    \"\"\"Call the api https://api.wheather.com/ with a POST request to obtain wheather data over mexico\n",
    "    The Post request should have the following body if the city is Mexico City\n",
    "    {\n",
    "        \"city\": \"Mexico City\",\n",
    "        \"country\": \"Mexico\"\n",
    "    }\n",
    "    The Posr request should have the following body if the city is Cancun\n",
    "    {\n",
    "        \"city\": \"Cancun\",\n",
    "        \"country\": \"Mexico\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    print('ok')\n",
    "    return 'ok'\n",
    "@tool\n",
    "def create_charts(code: Annotated[str, \"the code to create charts with matplotlib\"]):\n",
    "    \"\"\"Create a chart with matplotlib\"\"\"\n",
    "    return 'ok'\n",
    "\n",
    "\n",
    "@tool\n",
    "def stampa_qualcosa():\n",
    "    \"\"\"Stampa qualcosa\"\"\"  \n",
    "    \n",
    "    print('ok')\n",
    "    return 'ok'\n",
    "\n",
    "@tool\n",
    "def stampa_qualcosa_di_strano():\n",
    "    \"\"\"Stampa qualcosa di strano\"\"\"  \n",
    "    \n",
    "    print('ok')\n",
    "    return 'ok'\n",
    "\n",
    "\n",
    "tools = [info_messico,stampa_qualcosa, stampa_qualcosa_di_strano,create_charts]\n",
    "functions = [convert_to_openai_function(t) for t in tools]\n",
    "\n",
    "functions[0]\n",
    "message = model.invoke(\n",
    "    [HumanMessage(content=\"Give me the weather of cancun\")], functions=functions\n",
    "    #[HumanMessage(content=\"Creami un grafico sull'andamento del bitcoin\")], functions=functions\n",
    ")\n",
    "message\n",
    "\n",
    "\n"
   ],
   "id": "3545ddfe8e609dca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"request\":\"{\\\\\"city\\\\\": \\\\\"Cancun\\\\\", \\\\\"country\\\\\": \\\\\"Mexico\\\\\"}\"}', 'name': 'info_messico'}}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 189, 'total_tokens': 218}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'function_call', 'logprobs': None}, id='run-5e086cc5-5734-451a-b132-f7161ef4068d-0', usage_metadata={'input_tokens': 189, 'output_tokens': 29, 'total_tokens': 218})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
